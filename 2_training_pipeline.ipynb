{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00c0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tạo class Dataset để fetch dữ liệu\n",
    "# 2. Khảo sát phân phối của dữ liệu và chuẩn hóa trọng số để cân chỉnh mức độ phụ thuộc\n",
    "# 3. Cắt nhỏ dataset ra làm nhiều phần để train dần và vẫn đảm bảo phân bố của dữ liệu\n",
    "# 4. Tạo Dataloader cho tập train và valid\n",
    "# 5. Xây dựng mô hình, hàm thất thoát, bộ tối ưu và chọn siêu tham số\n",
    "# 6. Tạo cái j đó để theo dõi đánh giá và lưu lại quá trình huấn luyện mô hình\n",
    "# 7. Huấn luyện mô hình\n",
    "# 8. Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872734f4",
   "metadata": {},
   "source": [
    "## 0. Import configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfcee564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as f:\n",
    "    conf = yaml.safe_load(f)\n",
    "\n",
    "x_train_path = conf['dataset']['x_train']\n",
    "y_train_path = conf['dataset']['y_train']\n",
    "\n",
    "x_valid_path = conf['dataset']['x_valid']\n",
    "y_valid_path = conf['dataset']['y_valid']\n",
    "\n",
    "batch_size = conf['parameter']['batch_size']\n",
    "learning_rate = conf['parameter']['learning_rate']\n",
    "epochs = conf['parameter']['epochs']\n",
    "num_chunk = conf['chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cb300",
   "metadata": {},
   "source": [
    "## 1. Create Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5077d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập train: 10015\n",
      "Kích thước tập validation: 193\n"
     ]
    }
   ],
   "source": [
    "# 1. Create dataset class\n",
    "class HAM10KDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.class_cols = ['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
    "        # Create a mapping from class name to numerical label\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.class_cols)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get image\n",
    "        img_name = self.labels_df.iloc[idx]['image'] + '.jpg'\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # get numerical label\n",
    "        encode_label = self.labels_df.iloc[idx][self.class_cols].values\n",
    "        string_label = self.class_cols[encode_label.argmax()]\n",
    "        numerical_label = self.class_to_idx[string_label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, numerical_label\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = HAM10KDataset(\n",
    "    csv_path=y_train_path,   # CSV\n",
    "    img_dir=x_train_path,    # thư mục ảnh\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "valid_set = HAM10KDataset(\n",
    "    csv_path=y_valid_path,\n",
    "    img_dir=x_valid_path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Kích thước tập train: {len(train_set)}\")\n",
    "print(f\"Kích thước tập validation: {len(valid_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66e0ad",
   "metadata": {},
   "source": [
    "## 2. Examine data distribution and Calculate Classes' Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "606fba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MEL': 1113, 'NV': 6705, 'BCC': 514, 'AKIEC': 327, 'BKL': 1099, 'DF': 115, 'VASC': 142}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03958192, 0.00657042, 0.08570948, 0.13472377, 0.04008614,\n",
       "       0.3830841 , 0.31024417])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = train_set.labels_df\n",
    "class_cols = train_set.class_cols\n",
    "class_counts = {cls: 0 for cls in class_cols}\n",
    "\n",
    "for i, row in y_train_df.iterrows():\n",
    "    for cls in class_cols:\n",
    "        if row[cls] == 1:\n",
    "            class_counts[cls] += 1\n",
    "            break\n",
    "\n",
    "print(class_counts)\n",
    "\n",
    "total = len(y_train_df)\n",
    "num_classes = len(class_cols)\n",
    "\n",
    "class_weights = []\n",
    "for cls_name in class_cols:\n",
    "    count = class_counts[cls_name]\n",
    "    weight = total / (num_classes * count)\n",
    "    class_weights.append(weight)\n",
    "\n",
    "class_weights = np.array(class_weights)\n",
    "class_weights = class_weights / class_weights.sum() # chuẩn hóa để để đưa vào hàm Focal loss\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e568f",
   "metadata": {},
   "source": [
    "## 3. Chunking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b12b45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 with 1002 samples\n",
      "{0: 111, 1: 671, 2: 52, 3: 32, 4: 110, 5: 12, 6: 14}\n",
      "Chunk 2 with 1002 samples\n",
      "{0: 111, 1: 671, 2: 52, 3: 32, 4: 110, 5: 12, 6: 14}\n",
      "Chunk 3 with 1002 samples\n",
      "{0: 111, 1: 671, 2: 52, 3: 33, 4: 110, 5: 11, 6: 14}\n",
      "Chunk 4 with 1002 samples\n",
      "{0: 111, 1: 671, 2: 51, 3: 33, 4: 110, 5: 11, 6: 15}\n",
      "Chunk 5 with 1002 samples\n",
      "{0: 111, 1: 671, 2: 51, 3: 33, 4: 110, 5: 11, 6: 15}\n",
      "Chunk 6 with 1001 samples\n",
      "{0: 112, 1: 670, 2: 51, 3: 33, 4: 110, 5: 11, 6: 14}\n",
      "Chunk 7 with 1001 samples\n",
      "{0: 112, 1: 670, 2: 51, 3: 33, 4: 110, 5: 11, 6: 14}\n",
      "Chunk 8 with 1001 samples\n",
      "{0: 112, 1: 670, 2: 51, 3: 33, 4: 109, 5: 12, 6: 14}\n",
      "Chunk 9 with 1001 samples\n",
      "{0: 111, 1: 670, 2: 51, 3: 33, 4: 110, 5: 12, 6: 14}\n",
      "Chunk 10 with 1001 samples\n",
      "{0: 111, 1: 670, 2: 52, 3: 32, 4: 110, 5: 12, 6: 14}\n"
     ]
    }
   ],
   "source": [
    "# Chunking dataset into 10 small subset with the same distribution\n",
    "labels = np.argmax(train_set.labels_df[train_set.class_cols].values, axis=1)\n",
    "indices = np.arange(len(train_set))\n",
    "\n",
    "# Đảm bảo mỗi tập con đều vẫn giữ nguyên phân phối như tập lớn\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=num_chunk,\n",
    "    shuffle=True,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "k_chunk_indices = []\n",
    "for fold_id, (whatisthis, chunk_indices) in enumerate(skf.split(indices, labels)):\n",
    "    print(f\"Chunk {fold_id+1} with {len(chunk_indices)} samples\")\n",
    "    count = Counter(labels[chunk_indices])\n",
    "    count = {int(k): int(v) for k, v in count.items()}\n",
    "    print(dict(sorted(count.items())))\n",
    "    k_chunk_indices.append(chunk_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f7513",
   "metadata": {},
   "source": [
    "## 4. Create DataLoader for train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e60d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x1fb93bcb1a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a6443e0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a644230>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a646f30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a644620>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a644d10>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a6455e0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a644740>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a6443b0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1fb9a6441d0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loader = DataLoader(valid_set, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "chunk_loaders = []\n",
    "\n",
    "for i, chunk_indices in enumerate(k_chunk_indices):\n",
    "    chunk_subset = Subset(\n",
    "        train_set,\n",
    "        chunk_indices\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        chunk_subset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    chunk_loaders.append(loader)\n",
    "\n",
    "chunk_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43a068",
   "metadata": {},
   "source": [
    "## 5. Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da4b8d",
   "metadata": {},
   "source": [
    "### 5.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d327a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        # Depthwise convolution\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                in_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                groups=in_channels,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Pointwise convolution\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5c0f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV1(nn.Module):\n",
    "    def __init__(self, num_classes=7, width_mult=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        def c(ch):\n",
    "            return int(ch * width_mult)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv 1\n",
    "            nn.Conv2d(3, c(32), kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c(32)),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Depthwise blocks\n",
    "            DepthwiseSeparableConv(c(32),  c(64),  stride=1),\n",
    "            DepthwiseSeparableConv(c(64),  c(128), stride=2),\n",
    "            DepthwiseSeparableConv(c(128), c(128), stride=1),\n",
    "            DepthwiseSeparableConv(c(128), c(256), stride=2),\n",
    "            DepthwiseSeparableConv(c(256), c(256), stride=1),\n",
    "            DepthwiseSeparableConv(c(256), c(512), stride=2),\n",
    "\n",
    "            # 5 × (512 → 512)\n",
    "            DepthwiseSeparableConv(c(512), c(512), stride=1),\n",
    "            DepthwiseSeparableConv(c(512), c(512), stride=1),\n",
    "            DepthwiseSeparableConv(c(512), c(512), stride=1),\n",
    "            DepthwiseSeparableConv(c(512), c(512), stride=1),\n",
    "            DepthwiseSeparableConv(c(512), c(512), stride=1),\n",
    "\n",
    "            DepthwiseSeparableConv(c(512), c(1024), stride=2),\n",
    "            DepthwiseSeparableConv(c(1024), c(1024), stride=1),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(c(1024), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c98ce",
   "metadata": {},
   "source": [
    "### 5.2 Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b82927a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FocalLoss class defined.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.register_buffer(\n",
    "            \"alpha\", torch.tensor(alpha, dtype=torch.float32)\n",
    "        )\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-ce)\n",
    "        alpha_t = self.alpha.to(logits.device)[targets]\n",
    "        loss = alpha_t * (1 - pt) ** self.gamma * ce\n",
    "        return loss.mean()\n",
    "\n",
    "print(\"FocalLoss class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad429595",
   "metadata": {},
   "source": [
    "### 5.3 Model operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f27bafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation epoch functions defined.\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    runnning_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for imgs, labels in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runnning_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = runnning_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "            correct_prediction += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_prediction / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Training and validation epoch functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd163b1",
   "metadata": {},
   "source": [
    "## 6. Creat model checkpoint save/loader + Metrics log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29434e",
   "metadata": {},
   "source": [
    "### 6.1 Checkpoints save/loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ea33bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv, os, json\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "def save_checkpoint(\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        metrics,\n",
    "        save_dir\n",
    "):\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"metrics\": metrics,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    path = f\"{save_dir}/checkpoint/epoch_{epoch:02d}.pt\"\n",
    "    torch.save(ckpt, path)\n",
    "\n",
    "def load_checkpoint(dir_path, model, optimizer, device):\n",
    "    ckpt_files = [\n",
    "        f for f in os.listdir(dir_path)\n",
    "        if f.endswith(\".pt\")\n",
    "    ]\n",
    "\n",
    "    if len(ckpt_files) != 0:\n",
    "        \n",
    "        #Sort theo epoch\n",
    "        ckpt_files.sort()\n",
    "        latest_ckpt = ckpt_files[-1]\n",
    "\n",
    "        ckpt_path = os.path.join(dir_path, latest_ckpt)\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "\n",
    "        start_epoch = ckpt[\"epoch\"] + 1\n",
    "        metrics = ckpt.get(\"metrics\")\n",
    "        \n",
    "        print(f\"[INFO] Resume training from {latest_ckpt}\")\n",
    "        print(f\"       Continue with epoch {start_epoch} with valid acc {metrics['val_acc']:.4f}\")\n",
    "    else:\n",
    "        print(f\"[INFO] No checkpoints found ! Consider start training some..\")\n",
    "        model = None\n",
    "        optimizer = None\n",
    "        start_epoch = 0\n",
    "        best_acc = 0\n",
    "\n",
    "    return model, optimizer, start_epoch, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429eaa2",
   "metadata": {},
   "source": [
    "### 6.2 Metrics log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc06cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_csv(path, row):\n",
    "    write_header = not os.path.exists(path)\n",
    "\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "def log_to_json(path, entry):\n",
    "    if os.path.exists(path):\n",
    "        with open(path,\"r\") as f:\n",
    "            logs = json.load(f)\n",
    "    else:\n",
    "        logs = []\n",
    "\n",
    "    entry[\"timestamp\"] = datetime.now().isoformat()\n",
    "    logs.append(entry)\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(logs, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8dc777",
   "metadata": {},
   "source": [
    "## 7. Train mô hình thôi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8a8a2e",
   "metadata": {},
   "source": [
    "### 7.1 Khởi tạo tham số training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b180eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Resume training from epoch_03.pt\n",
      "       Continue with epoch 4 with valid acc 0.6580\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập mô hình\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "resume_ckpt_path = r\"experiments\\mobilenetv1_ham10k\\checkpoint\"\n",
    "\n",
    "model = MobileNetV1(num_classes=7).to(device)\n",
    "criterion = FocalLoss(alpha=class_weights, gamma=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "model, optimizer, start_epoch, metrics = load_checkpoint(resume_ckpt_path, model, optimizer, device)\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "best_acc = metrics['val_acc']\n",
    "\n",
    "# Log theo dõi thông số\n",
    "save_dir = \"experiments/mobilenetv1_ham10k\"\n",
    "os.makedirs(f\"{save_dir}/checkpoint\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/logs\", exist_ok=True)\n",
    "\n",
    "csv_log_path = f\"{save_dir}/logs/train_log.csv\"\n",
    "json_log_path = f\"{save_dir}/logs/train_log.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d94323d",
   "metadata": {},
   "source": [
    "### 7.2 Training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "55c08864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n",
      "Epoch 4/10\n",
      "     Chunk 1/10 - Train Loss: 0.0234, Train Acc: 0.5190 - Val Loss: 0.0324, Val Acc: 0.4715 - Time: 121.72s\n",
      "     Chunk 2/10 - Train Loss: 0.0231, Train Acc: 0.5509 - Val Loss: 0.0293, Val Acc: 0.5544 - Time: 126.88s\n",
      "     Chunk 3/10 - Train Loss: 0.0224, Train Acc: 0.5200 - Val Loss: 0.0262, Val Acc: 0.5492 - Time: 126.10s\n",
      "     Chunk 4/10 - Train Loss: 0.0242, Train Acc: 0.4970 - Val Loss: 0.0242, Val Acc: 0.6114 - Time: 136.09s\n",
      "     Chunk 5/10 - Train Loss: 0.0208, Train Acc: 0.5070 - Val Loss: 0.0263, Val Acc: 0.6166 - Time: 150.41s\n",
      "     Chunk 6/10 - Train Loss: 0.0215, Train Acc: 0.5315 - Val Loss: 0.0237, Val Acc: 0.5492 - Time: 129.34s\n",
      "     Chunk 7/10 - Train Loss: 0.0223, Train Acc: 0.4875 - Val Loss: 0.0217, Val Acc: 0.6062 - Time: 200.19s\n",
      "     Chunk 8/10 - Train Loss: 0.0227, Train Acc: 0.5465 - Val Loss: 0.0248, Val Acc: 0.5596 - Time: 168.77s\n",
      "     Chunk 9/10 - Train Loss: 0.0219, Train Acc: 0.5495 - Val Loss: 0.0309, Val Acc: 0.6891 - Time: 151.71s\n",
      "  --> Best model saved with Validation Accuracy: 0.6891\n",
      "     Chunk 10/10 - Train Loss: 0.0209, Train Acc: 0.5744 - Val Loss: 0.0283, Val Acc: 0.6425 - Time: 174.57s\n",
      "Epoch 5/10\n",
      "     Chunk 1/10 - Train Loss: 0.0201, Train Acc: 0.5549 - Val Loss: 0.0382, Val Acc: 0.5285 - Time: 186.34s\n",
      "     Chunk 2/10 - Train Loss: 0.0220, Train Acc: 0.5529 - Val Loss: 0.0274, Val Acc: 0.5803 - Time: 176.60s\n",
      "     Chunk 3/10 - Train Loss: 0.0234, Train Acc: 0.4910 - Val Loss: 0.0217, Val Acc: 0.6425 - Time: 174.83s\n",
      "     Chunk 4/10 - Train Loss: 0.0226, Train Acc: 0.5399 - Val Loss: 0.0254, Val Acc: 0.5959 - Time: 167.09s\n",
      "     Chunk 5/10 - Train Loss: 0.0206, Train Acc: 0.5379 - Val Loss: 0.0247, Val Acc: 0.5959 - Time: 162.13s\n",
      "     Chunk 6/10 - Train Loss: 0.0189, Train Acc: 0.5544 - Val Loss: 0.0242, Val Acc: 0.5959 - Time: 129.50s\n",
      "     Chunk 7/10 - Train Loss: 0.0194, Train Acc: 0.5415 - Val Loss: 0.0280, Val Acc: 0.6425 - Time: 122.66s\n",
      "     Chunk 8/10 - Train Loss: 0.0180, Train Acc: 0.5584 - Val Loss: 0.0256, Val Acc: 0.6425 - Time: 123.06s\n",
      "     Chunk 9/10 - Train Loss: 0.0217, Train Acc: 0.5714 - Val Loss: 0.0244, Val Acc: 0.5596 - Time: 124.39s\n",
      "     Chunk 10/10 - Train Loss: 0.0225, Train Acc: 0.5604 - Val Loss: 0.0275, Val Acc: 0.5699 - Time: 138.22s\n",
      "Epoch 6/10\n",
      "     Chunk 1/10 - Train Loss: 0.0217, Train Acc: 0.4900 - Val Loss: 0.0317, Val Acc: 0.5440 - Time: 111.58s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m epoch_start_time = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m train_losses.append(train_loss)\n\u001b[32m     11\u001b[39m train_accuracies.append(train_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     14\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     16\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m runnning_loss += loss.item() * imgs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     20\u001b[39m _, predicted = torch.max(outputs.data, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    533\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training ...\")\n",
    "\n",
    "for epoch in range(start_epoch-1, epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i, train_loader in enumerate(chunk_loaders):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate_epoch(model, valid_loader, criterion, device)        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f'     Chunk {i+1}/{num_chunk} - ' \\\n",
    "            f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - ' \\\n",
    "            f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} - ' \\\n",
    "            f'Time: {(time.time() - epoch_start_time):.2f}s')\n",
    "\n",
    "        # kiếm chỗ để bổ sung thêm hàm log để theo dõi metrics và lưu thông số mô hình lại\n",
    "        csv_row = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"chunk_id\": i + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        }\n",
    "        log_to_csv(csv_log_path, csv_row)\n",
    "\n",
    "        json_entry = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"chunk_id\": i + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "        }\n",
    "        log_to_json(json_log_path, json_entry)\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), f'{save_dir}/best_mobilenetv1_model.pth')\n",
    "            print(f\"  --> Best model saved with Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    # Lưu checkpoint tại mỗi epoch\n",
    "    save_checkpoint(model=model, optimizer=optimizer, epoch=epoch+1, metrics=json_entry, save_dir=save_dir)\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256c6ea",
   "metadata": {},
   "source": [
    "## 8. Đánh giá mô hình\n",
    "Confusion matrix, accuracy, recall, precision, f1-score,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbde19",
   "metadata": {},
   "source": [
    "### 8.1 Suy luận trên tập Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb9ef5",
   "metadata": {},
   "source": [
    "### 8.2 Visualize kết quả"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
